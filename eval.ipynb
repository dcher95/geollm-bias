{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01/06/2025'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(pd.read_csv(\"/data/cher/geollm-bias/data/eButterfly.csv\")['date'][0]).strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- percentage of the time it says \"I don't have enough information...\" # \"enough information\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from utils import extract_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_files(directory):\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            df = pd.read_json(filepath).T\n",
    "            data.append(df)\n",
    "    return pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'eButterfly'\n",
    "coordinates_csv = \"/data/cher/geollm-bias/data/eButterfly.csv\"\n",
    "prompt_types = [\"basic_only_coords\", \"basic\", \"expert\", \"incontext\", \"incontext_expert\", \"temporal_expert\"]\n",
    "\n",
    "actuals = pd.read_csv(coordinates_csv)\n",
    "\n",
    "predictions = []\n",
    "for i, prompt_type in enumerate(prompt_types):\n",
    "    # read predictions\n",
    "    data = read_json_files(f'/data/cher/geollm-bias/output/eButterfly/preds/llm_params_1/{prompt_type}')\n",
    "    data.index = data['index']\n",
    "    data.sort_index(inplace=True)\n",
    "\n",
    "    # correct estimate if na\n",
    "    data['prediction'] = data['response'].apply(lambda x: extract_estimate(x, prompt_type=prompt_type) if pd.notna(x) else None)\n",
    "\n",
    "    # Save the results to CSV\n",
    "    data.to_csv(f'./errors/{prompt_type}_check_corrections.csv', index=False, encoding='utf-8')\n",
    "\n",
    "    # No need to keep all the columns\n",
    "    if i  > 0:\n",
    "        data = pd.DataFrame(data['prediction'])\n",
    "\n",
    "    data.rename(columns = {'prediction' : f'{prompt_type}_prediction'}, inplace = True)\n",
    "\n",
    "\n",
    "    # Add to list\n",
    "    predictions.append(data)\n",
    "\n",
    "# combine predictions\n",
    "data = pd.concat(predictions, axis=1)\n",
    "\n",
    "# combine predicted with actuals\n",
    "data = pd.merge(data, actuals[['Presence']], left_index=True, right_index=True)\n",
    "\n",
    "numeric_cols = list(set(data.columns) -  set(['species', 'index', 'latitude', 'longitude', 'response']))\n",
    "data[numeric_cols] = data[numeric_cols].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species                           0\n",
       "index                             0\n",
       "latitude                          0\n",
       "longitude                         0\n",
       "response                          0\n",
       "basic_only_coords_prediction    496\n",
       "basic_prediction                  7\n",
       "expert_prediction                17\n",
       "incontext_prediction             49\n",
       "incontext_expert_prediction      30\n",
       "temporal_expert_prediction       14\n",
       "Presence                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic_only_coords_prediction</th>\n",
       "      <th>basic_prediction</th>\n",
       "      <th>expert_prediction</th>\n",
       "      <th>incontext_prediction</th>\n",
       "      <th>incontext_expert_prediction</th>\n",
       "      <th>temporal_expert_prediction</th>\n",
       "      <th>Presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>989.000000</td>\n",
       "      <td>957.000000</td>\n",
       "      <td>976.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>1006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.134854</td>\n",
       "      <td>2.231532</td>\n",
       "      <td>3.627098</td>\n",
       "      <td>5.308777</td>\n",
       "      <td>7.500512</td>\n",
       "      <td>5.741532</td>\n",
       "      <td>0.907555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34.571578</td>\n",
       "      <td>1.994978</td>\n",
       "      <td>2.786345</td>\n",
       "      <td>3.563766</td>\n",
       "      <td>3.806633</td>\n",
       "      <td>5.049797</td>\n",
       "      <td>0.289798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.900000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.900000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       basic_only_coords_prediction  basic_prediction  expert_prediction  \\\n",
       "count                    891.000000        999.000000         989.000000   \n",
       "mean                       9.134854          2.231532           3.627098   \n",
       "std                       34.571578          1.994978           2.786345   \n",
       "min                        0.000000          0.000000           0.000000   \n",
       "25%                        6.400000          0.000000           0.000000   \n",
       "50%                        9.900000          3.000000           4.200000   \n",
       "75%                        9.900000          4.000000           5.000000   \n",
       "max                     1000.000000          9.900000           9.900000   \n",
       "\n",
       "       incontext_prediction  incontext_expert_prediction  \\\n",
       "count            957.000000                   976.000000   \n",
       "mean               5.308777                     7.500512   \n",
       "std                3.563766                     3.806633   \n",
       "min                0.000000                     0.000000   \n",
       "25%                0.000000                     4.500000   \n",
       "50%                8.100000                     9.900000   \n",
       "75%                8.100000                    10.000000   \n",
       "max                9.900000                    10.000000   \n",
       "\n",
       "       temporal_expert_prediction     Presence  \n",
       "count                  992.000000  1006.000000  \n",
       "mean                     5.741532     0.907555  \n",
       "std                      5.049797     0.289798  \n",
       "min                      0.000000     0.000000  \n",
       "25%                      0.000000     1.000000  \n",
       "50%                      7.500000     1.000000  \n",
       "75%                      9.900000     1.000000  \n",
       "max                     94.000000     1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General dataset metrics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Prediction Column  Average Precision  Average Precision (Even)  \\\n",
      "0  basic_only_coords_prediction           0.885534                  0.457730   \n",
      "1              basic_prediction           0.900612                  0.489834   \n",
      "2             expert_prediction           0.891430                  0.442275   \n",
      "3          incontext_prediction           0.900531                  0.502776   \n",
      "4   incontext_expert_prediction           0.903075                  0.490463   \n",
      "5    temporal_expert_prediction           0.913888                  0.548036   \n",
      "\n",
      "   Accuracy  Accuracy (Even)  \n",
      "0  0.718294         0.466292  \n",
      "1  0.120120         0.516129  \n",
      "2  0.274014         0.437500  \n",
      "3  0.589342         0.472527  \n",
      "4  0.687500         0.477528  \n",
      "5  0.580645         0.532609  \n"
     ]
    }
   ],
   "source": [
    "# Classification metrics\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, accuracy_score\n",
    ")\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "# List of prediction columns\n",
    "prediction_cols = [\n",
    "    \"only_coords_prediction\",\n",
    "    \"basic_prediction\",\n",
    "    \"expert_prediction\",\n",
    "    \"incontext_prediction\",\n",
    "    \"temporal_prediction\"\n",
    "]\n",
    "\n",
    "# Initialize results list\n",
    "results = []\n",
    "\n",
    "for col in prediction_cols:\n",
    "    if col not in data.columns:\n",
    "        continue  # Skip if the column is missing\n",
    "    \n",
    "    # Drop NaN values for fair comparison\n",
    "    valid_df = data[[col, \"Presence\"]].dropna()\n",
    "\n",
    "    # Convert to 0 to 1 for better comparison\n",
    "    valid_df[col] = valid_df[col] / 9.9\n",
    "    valid_df[col] = valid_df[col].clip(upper=1)\n",
    "    \n",
    "    if valid_df.empty:\n",
    "        continue  # Skip if no valid data\n",
    "\n",
    "    # Calculate metrics\n",
    "    ap_score = average_precision_score(valid_df[\"Presence\"], valid_df[col])\n",
    "\n",
    "    binary_preds = valid_df[col].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "    acc_score = accuracy_score(valid_df[\"Presence\"], binary_preds)\n",
    "\n",
    "    # average precision if we make 0 and 1 equivalent\n",
    "    num_absence = (valid_df['Presence'] == 0).sum()\n",
    "    presence_predictions = valid_df[valid_df['Presence'] == 1].sample(n=num_absence)\n",
    "    valid_df = pd.concat([valid_df[valid_df['Presence'] == 0], presence_predictions])\n",
    "\n",
    "    even_ap_score = average_precision_score(valid_df[\"Presence\"], valid_df[col])\n",
    "\n",
    "    binary_preds = valid_df[col].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "    even_acc_score = accuracy_score(valid_df[\"Presence\"], binary_preds)\n",
    "\n",
    "    # mean average precision score by species\n",
    "\n",
    "    # average precision by observational density\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Prediction Column\": col,\n",
    "        \"Average Precision\": ap_score,\n",
    "        \"Average Precision (Even)\": even_ap_score,\n",
    "        \"Accuracy\": acc_score,\n",
    "        \"Accuracy (Even)\": even_acc_score,\n",
    "        # \"Mean Average Precision\": mean_ap_score,\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "summary_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results\n",
    "print(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clippatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
